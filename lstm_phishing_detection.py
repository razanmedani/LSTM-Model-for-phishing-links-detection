# -*- coding: utf-8 -*-
"""LSTM_phishing_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qrjGKga-S8VZLOjoAfchBgFG4w6welrb
"""

import csv
import random
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.layers.embeddings import Embedding
from keras.preprocessing.sequence import pad_sequences
from keras.preprocessing.text import Tokenizer
from sklearn.metrics import confusion_matrix

X=[]
Y=[]
with open("/content/last-data.csv" ,'r') as f:
  data = csv.reader(f)
  #next(data)
  for row in data:
    url= row[0]
    label= row[1]
    X.append(url)
    Y.append(label)

train_size =int(len(X) * 0.75)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = np.array(Y[:train_size]), np.array(Y[train_size:len(Y)])
Y_train, Y_test = Y_train.reshape(Y_train.shape[0],1), Y_test.reshape(Y_test.shape[0],1)
#Y_test= Y[train_size:len(Y)]
print('all data:', len(X))
print( 'train data:',len(X_train),'  test data:', len(X_test))
print(Y_train.shape, Y_test.shape)

tokenizer = Tokenizer(filters='\t\n', char_level=True)
tokenizer.fit_on_texts(X_train)

word_index = tokenizer.word_index
print(word_index)

num_words = len(word_index) + 1
X_train = tokenizer.texts_to_sequences(X_train)
print ('example:',X[0])

max_length = 2083
X_train = pad_sequences(X_train, maxlen=max_length , padding = 'pre')
X_test = tokenizer.texts_to_sequences(X_test)
X_test = pad_sequences(X_test, maxlen=max_length , padding = 'pre')

X_train, X_test = X_train.astype(float), X_test.astype(float)
Y_train, Y_test = Y_train.astype(float), Y_test.astype(float)

model = Sequential()
model.add(Embedding(num_words, 64, input_length=max_length , name="embedding-1" ))
model.add(LSTM(32, return_sequences=True, name="LSTM-1" ))
model.add(LSTM(64,return_sequences=True ,name="LSTM-2"))
model.add(LSTM(128 , name="LSTM-3" ))
model.add(Dense(20, activation='relu' , name="FC-1" ))
model.add(Dropout(0.2 , name="dropout-1"))
model.add(Dense(1, activation='sigmoid', name="FC-2"))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',"val_acc"])
print(model.summary())
tf.keras.utils.plot_model(model, to_file="model.png", show_shapes=True ,  show_layer_names=True,)

from keras.models import load_model 

weights_file = '/content/lstm2-weights.h5'
model =load_model ('/content/lstm2-model.h5')
model.load_weights(weights_file)

# No need to fit data Model is already trained
#model.fit(X_train, Y_train, epochs=18 , batch_size= 1 , validation_split=0.25 )

score, acc = model.evaluate(X_test, Y_test, verbose=1)

numbers = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]
lstm_acc = [0.8023,0.9221 ,0.8711,0.9136,0.9451,0.9550,0.9573,0.9442,0.9610 ,0.9587 ,0.9622,0.9722,0.9780,0.9821,0.9833,0.9855,0.9860, 0.9854]
lstm_validation_acc = [0.8973,0.9395,0.8691,0.9322,0.9269,0.9611,0.9589,0.9621,0.9653,0.9662,0.9654,0.9798,0.9844,0.9825,0.9848,0.9859,0.9840,0.9836]
plt.plot(numbers, lstm_acc, 'b', label='Training Accuracy')
plt.plot(numbers, lstm_validation_acc, 'r--', label='Validation accuracy')
#plt.scatter(numbers,lstm_acc, s=100)
#plt.scatter(numbers,lstm_validation_acc, s=100)
plt.xlabel("number of Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title('Training & Validation Accuracy Comparison')

plt.show()

numbers = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]
lstm_loss = [0.4031 ,0.2089 ,0.2913 ,0.2256 ,0.1580,0.1312,0.1242 ,0.1605 ,0.1159,0.1179,0.1091,0.0839,0.0677,0.0568,0.0541,0.0494,0.0469,0.0480]
lstm_validation_loss = [0.2459 ,0.1603,0.3031,0.1834,0.1939 ,0.1179 , 0.1197 ,0.1190 ,0.1065 ,0.1031,0.1086,0.0681,0.0571,0.0574 ,0.0513,0.0485,0.0507,0.0532 ]
plt.plot(numbers, lstm_loss, 'b', label='Training Loss')
plt.plot(numbers, lstm_validation_loss, 'r--', label='Validation Loss')
#plt.scatter(numbers,lstm_acc, s=100)
#plt.scatter(numbers,lstm_validation_acc, s=100)
plt.xlabel("number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.title('Training & Validation Loss Comparison')

plt.show()

y_pred = model.predict(X_test)
#cm = confusion_matrix(Y_test, y_pred)
print(y_pred)
Y_pred_new= []
for y in y_pred:
  if y>0.5:
    Y_pred_new.append(1)
  else:
    Y_pred_new.append(0)

Y_pred_new = np.array(Y_pred_new)
Y_pred_new = Y_pred_new.reshape(Y_pred_new.shape[0],1).astype(float)
print("NEW:", Y_pred_new,"TEST:", Y_test)

cm = confusion_matrix(Y_test, Y_pred_new)
print(cm)